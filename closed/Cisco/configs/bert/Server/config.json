{
    "A100-PCIex2": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 2635
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 975
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "server_target_qps": 525,
                "precision": "fp16"
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 64,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 2,
        "server_target_qps": 4879,
        "soft_drop": 1.0,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "A100-SXM4x1": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 1550
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 620
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "server_target_qps": 310,
                "precision": "fp16"
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 64,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 2,
        "server_target_qps": 3100,
        "soft_drop": 0.99,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "A100-SXM4x8": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "gpu_batch_size": 64,
                "precision": "fp16",
                "server_target_qps": 12450
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 5000
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "gpu_batch_size": 64,
                "precision": "fp16",
                "server_target_qps": 2500
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 96,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 240,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 0,
        "server_target_qps": 24950,
        "soft_drop": 0.99,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "T4x1": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 0,
                "server_target_qps": 160,
                "graph_specs": "(128, 4, 256, 4), (192, 128, 512, 4), (256, 192, 1536, 8), (384, 256, 2048, 16)"
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 72
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 0,
                "server_target_qps": 32,
                "graph_specs": "(128, 4, 256, 4), (192, 128, 512, 4), (256, 192, 1536, 8), (384, 256, 2048, 16)"
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 240,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 0,
        "server_target_qps": 360,
        "soft_drop": 0.993,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "T4x20": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 20,
                "server_target_qps": 3750,
                "soft_drop": 0.992
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 1560
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 20,
                "server_target_qps": 750,
                "soft_drop": 0.992
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 260,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 40,
        "server_target_qps": 7800,
        "soft_drop": 0.992,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "T4x8": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 8,
                "server_target_qps": 1480
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 620
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 8,
                "server_target_qps": 295
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 260,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 16,
        "server_target_qps": 3100,
        "soft_drop": 0.992,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "T4x6": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 6,
                "server_target_qps": 1110
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 470
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 6,
                "server_target_qps": 225
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 260,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 12,
        "server_target_qps": 2620,
        "soft_drop": 0.992,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "TitanRTXx1": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 580
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 220
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "precision": "fp16",
                "server_target_qps": 115
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 32,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 2,
        "server_target_qps": 1110,
        "soft_drop": 0.993,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "TitanRTXx4": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 2500
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 940
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "precision": "fp16",
                "gpu_batch_size": 32,
                "server_target_qps": 500
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 32,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 8,
        "server_target_qps": 4700,
        "soft_drop": 0.993,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "benchmark": "bert",
    "scenario": "Server"
}
