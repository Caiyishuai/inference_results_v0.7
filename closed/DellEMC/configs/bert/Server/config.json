{
    "XE2420_T4x4": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 4,
                "server_target_qps": 760
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 260,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 8,
        "server_target_qps": 1610,
        "soft_drop": 0.992,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "R740_T4x4": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 4,
                "server_target_qps": 680
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 2790
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 4,
                "server_target_qps": 1332
            }
        },
        "enable_interleaved": false,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 260,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 4,
        "server_target_qps": 1350,
        "soft_drop": 0.992,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "R7515_T4x4": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 4,
                "server_target_qps": 630
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 2790
            },
            "high_accuracy_triton": {
                "use_triton": false,
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 8,
                "server_target_qps": 1332
            }
        },
        "enable_interleaved": false,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 260,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 4,
        "server_target_qps": 1280,
        "soft_drop": 0.992,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "DSS8440_T4x12": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 12,
                "server_target_qps": 2200,
                "soft_drop": 0.992
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 260,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 24,
        "server_target_qps": 4750,
        "soft_drop": 0.992,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "DSS8440_QuadroRTX8000x8": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 4500
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 32,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 16,
        "server_target_qps": 8570,
        "soft_drop": 0.993,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "DSS8440_QuadroRTX6000x10": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 5600
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 32,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 20,
        "server_target_qps": 10650,
        "soft_drop": 0.993,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "R7525_A100x2": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 2430
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 64,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 2,
        "server_target_qps": 5100,
        "soft_drop": 1.0,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "R7525_A100x3": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 3700
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 64,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 2,
        "server_target_qps": 7500,
        "soft_drop": 1.0,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "R7525_QuadroRTX8000x3": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 1650,
                "gpu_batch_size": 28,
                "gpu_inference_streams": 2
            }
        },
        "enable_interleaved": false,
        "gpu_batch_size": 32,
        "gpu_copy_streams": 3,
        "gpu_inference_streams": 1,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 3,
        "server_target_qps": 2810,
        "soft_drop": 0.993,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "DSS8440_T4x16": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 16,
                "server_target_qps": 2977,
                "soft_drop": 0.992
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 260,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 32,
        "server_target_qps": 6231,
        "soft_drop": 0.992,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "DSS8440_QuadroRTX8000x10": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 5600
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 32,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 10,
        "server_target_qps": 10800,
        "soft_drop": 0.993,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "R7525_T4x8": {
        "active_sms": 60,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 8,
                "server_target_qps": 1420
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 2790 
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 8,
                "server_target_qps": 1332
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 260,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 16,
        "server_target_qps": 3000,
        "soft_drop": 0.992,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "C4140_QuadroRTX6000x4": {
        "active_sms": 100,
        "coalesced_tensor": true,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 2280
            },
            "triton": {
                "use_triton": true,
                "server_target_qps": 4700
            },
            "high_accuracy_triton": {
                "use_triton": true,
                "precision": "fp16",
                "gpu_batch_size": 32,
                "server_target_qps": 2250
            }
        },
        "enable_interleaved": true,
        "gpu_batch_size": 16, 
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "graphs_max_seqlen": 200,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "server_num_issue_query_threads": 8,
        "server_target_qps": 4240,
        "soft_drop": 0.993,
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "benchmark": "bert",
    "scenario": "Server"
}
