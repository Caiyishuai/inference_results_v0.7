# TensorFLow ResNet50-v1.5 for MLPerf v0.7 inference

## Description

The ResNet50 INT8 model is offline generated by [Intel Low Precision Optimization Tool](https://github.com/intel/lp-opt-tool.git) based on [FP32 model](https://zenodo.org/record/2535873/files/resnet50_v1.pb) and the calibration dataset provided by mlperf in [here](https://github.com/mlperf/inference/blob/master/calibration/ImageNet/cal_image_list_option_1.txt)

>> IntelÂ® Low Precision Optimization Tool(iLiT) is an open-source python library which is intended to deliver a unified low-precision inference interface cross multiple Intel optimized DL frameworks on both CPU and GPU. It supports automatic accuracy-driven tuning strategies, along with additional objectives like performance, model size, or memory footprint, to yield INT8 model

>> This tool(iLiT) by default supports post training static quantization, and takes "model"( FP32 model), "q_dataloader"(calibration dataloader) and "eval_dataloader"(evaluation function) as inputs. Calibration dataloader is used at calibration phase to collect tensor statistic info upon calibration dataset. Evaluation dataloader is used by iLiT to feed full validation dataset to get FP32 accuracy baseline and the accuracy of INT8 model generated by iLiT. iLiT relies on the evaluation dataloader to check if generated INT8 model meets pre-defined accuracy loss goal or not and decides whether goes through another tuning config, such as using different scheme (asym or sym), different granularity (per_tensor or per_channel), different calibration algorithm (minmax or kl).

The ResNet50 BF16 model is offline converted by auto-mixed-precision graph optimizer from TensorFlow.

## Steps for INT8 calibration

```bash

wget https://zenodo.org/record/2535873/files/resnet50_v1.pb
git clone https://github.com/intel/lp-opt-tool.git
cd lp-opt-tool
git apply ilit.patch
python setup.py install
cd ..
git clone --recurse-submodules https://github.com/mlperf/inference.git
cd inference
git reset --hard bfbda5fc419364c3f71b5b1640f6c00e7675b212
git apply mlperf.patch
cd vision/classification_and_detection
MODEL_DIR=<dir_to_resnet50_v1.pb> DATA_DIR=<dir_to_ILSVRC2012_img_val> ./run_local.sh tf resnet50 cpu --accuracy --calib-dataset-list=../../calibration/ImageNet/cal_image_list_option_1.txt --tune

```

A graph named int8_resnet50_v1.pb will be generated in the current working dir.

## Steps for generating BF16 model

TensorFlow framework has auto-mixed-precision grappler optimizer to convert several operators into bfloat16 precision for CPU. Run the following python script

```bash

TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_CLEARLIST_ADD=Pad,BiasAdd TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_GRAYLIST_REMOVE=BiasAdd python convert_fp32_to_bf16.py

```
